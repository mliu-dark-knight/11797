from pytorch_pretrained_bert import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

BIG_INT = 1e8
INVALID_INDEX = BIG_INT
SMALL_FLOAT = 1e-2
IGNORE_INDEX = -1
FULL_BATCH_KEY = 'full_batch'
CONTEXT_IDXS_KEY = 'context_idxs'
QUES_IDXS_KEY = 'ques_idxs'
CONTEXT_QUES_IDXS_KEY = 'context_ques_idxs'
COMPACT_CONTEXT_QUES_IDXS_KEY = 'compact_context_ques_idxs'
CONTEXT_QUES_MASKS_KEY = 'context_ques_masks'
COMPACT_CONTEXT_QUES_MASKS_KEY = 'compact_context_ques_masks'
CONTEXT_QUES_SEGMENTS_KEY = 'context_ques_segments'
COMPACT_CONTEXT_QUES_SEGMENTS_KEY = 'compact_context_ques_segments'
COMPACT_ANSWER_MASKS_KEY = 'compact_answer_masks'
ID_KEY = 'id'
IDS_KEY = 'ids'
IS_SUPPORT_KEY = 'is_support'
COMPACT_IS_SUPPORT_KEY = 'compact_is_support'
HAS_SP_KEY = 'has_sp_fact'
ALL_MAPPING_KEY = 'all_mapping'
COMPACT_ALL_MAPPING_KEY = 'compact_all_mapping'
Y1_KEY = 'y1'
COMPACT_Y1_KEY = 'compact_y1'
Y2_KEY = 'y2'
COMPACT_Y2_KEY = 'compact_y2'
Q_TYPE_KEY = 'q_type'
START_END_FACTS_KEY = 'start_end_facts'
COMPACT_TO_ORIG_MAPPING_KEY = 'compact_to_orig_mapping'
SEP = '[SEP]'
CLS = '[CLS]'
UNK = '[UNK]'
SEP_IDX = tokenizer.vocab[SEP]
CLS_IDX = tokenizer.vocab[CLS]
UNK_IDX = tokenizer.vocab[UNK]
PARA_LIMIT = 144
QUES_LIMIT = 64
ANS_LIMIT = 8
BERT_HIDDEN = 768
BERT_LIMIT = 512
